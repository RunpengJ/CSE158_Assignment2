{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "import json\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn import linear_model\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'r')\n",
    "  for l in g:\n",
    "    yield json.loads(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_reviews = [l for l in parse(\"review-Hawaii_10.json.gz\")]\n",
    "businesses = [l for l in parse(\"meta-Hawaii.json.gz\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID: 113965417079576625433, Average Rating: 4.91\n",
      "User ID: 116655819137293331166, Average Rating: 4.73\n",
      "User ID: 100834119994550070853, Average Rating: 4.94\n",
      "User ID: 103207214144482097315, Average Rating: 4.64\n",
      "User ID: 108526171163172578599, Average Rating: 3.48\n"
     ]
    }
   ],
   "source": [
    "#user avg rating\n",
    "user_ratings = {}\n",
    "\n",
    "for review in users_reviews:\n",
    "    user_id = review.get('user_id')\n",
    "    rating = review.get('rating')\n",
    "\n",
    "    if user_id is not None and rating is not None:\n",
    "        if user_id not in user_ratings:\n",
    "            user_ratings[user_id] = {'total_rating': 0, 'count': 0}\n",
    "        \n",
    "        user_ratings[user_id]['total_rating'] += rating\n",
    "        user_ratings[user_id]['count'] += 1\n",
    "\n",
    "user_avg_ratings = {user_id: data['total_rating'] / data['count'] \n",
    "                    for user_id, data in user_ratings.items() if data['count'] > 0}\n",
    "\n",
    "for user_id in list(user_avg_ratings.keys())[:5]:\n",
    "    print(f\"User ID: {user_id}, Average Rating: {user_avg_ratings[user_id]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#businuess img count\n",
    "image_counts = {}\n",
    "\n",
    "for review in users_reviews:\n",
    "    gmap_id = review.get('gmap_id')\n",
    "    images = review.get('pics')\n",
    "\n",
    "    if gmap_id and images:\n",
    "        num_images = len(images)\n",
    "        if gmap_id in image_counts:\n",
    "            image_counts[gmap_id] += num_images\n",
    "        else:\n",
    "            image_counts[gmap_id] = num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_counts = {}\n",
    "\n",
    "for review in users_reviews:\n",
    "    gmap_id = review.get('gmap_id')\n",
    "    response = review.get('resp')\n",
    "\n",
    "    if gmap_id and response:\n",
    "        if gmap_id in response_counts:\n",
    "            response_counts[gmap_id] += 1\n",
    "        else:\n",
    "            response_counts[gmap_id] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_data = [{'user_id': d['user_id'], 'gmap_id': d['gmap_id'], 'rating': d['rating'],'text': d['text']} \n",
    "              for d in users_reviews if 'user_id' in d and 'gmap_id' in d and 'rating' in d and 'text' in d]\n",
    "\n",
    "business_dict = {d['gmap_id']: {'avg_rating': d.get('avg_rating', 0), \n",
    "                                'num_of_reviews': d.get('num_of_reviews', 0)}\n",
    "                 for d in businesses if 'gmap_id' in d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [{'user_id': d['user_id'], 'gmap_id': d['gmap_id'], 'text': d['text'], \n",
    "             'user_avg_rating': user_avg_ratings[d['user_id']], \n",
    "             'response_count': response_counts.get(d['gmap_id'], 0), \n",
    "             'image_counts': image_counts.get(d['gmap_id'], 0),\n",
    "             'bus_avg_rating': business_dict[d['gmap_id']]['avg_rating'], \n",
    "             'num_of_reviews': business_dict[d['gmap_id']]['num_of_reviews']}\n",
    "            for d in users_reviews if 'user_id' in d and 'gmap_id' in d and 'rating' in d and 'text' in d]\n",
    "labels = [d['rating'] for d in users_reviews if 'user_id' in d and 'gmap_id' in d and 'rating' in d and 'text' in d]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(12345)\n",
    "combined = list(zip(features, labels))\n",
    "random.shuffle(combined)\n",
    "features[:], labels[:] = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': '118019878707665188743',\n",
       " 'gmap_id': '0x7eaad5b76010bf61:0xd3730662460d3b4f',\n",
       " 'text': 'Absolutely Beautiful! Stunning one of a kind views and Amazing eats! Enjoy!',\n",
       " 'user_avg_rating': 5.0,\n",
       " 'response_count': 3,\n",
       " 'image_counts': 24,\n",
       " 'bus_avg_rating': 4.2,\n",
       " 'num_of_reviews': 326}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x - y) ** 2 for x, y in zip(predictions, labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(predictions, labels):\n",
    "    differences = [abs(x - y) for x, y in zip(predictions, labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "split_index = int(len(features) * 0.9)\n",
    "train_features = features[:split_index]\n",
    "test_features = features[split_index:]\n",
    "train_labels = labels[:split_index]\n",
    "test_labels = labels[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314214"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowercase, punctuation removed, no stemming\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for d in train_features:\n",
    "    if d['text']:\n",
    "        r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "        ws = [w for w in r.split() if w not in stop_words]\n",
    "        for w in ws:\n",
    "            wordCount[w] += 1\n",
    "            \n",
    "len(wordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort(reverse=True)\n",
    "words = [x[1] for x in counts[:1500]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordID = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    if datum['text']:\n",
    "        r = ''.join([c for c in datum['text'].lower() if not c in punctuation])\n",
    "        ws = [w for w in r.split() if w not in stop_words]\n",
    "        for w in ws:\n",
    "            if w in words:\n",
    "                feat[wordID[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = [feature(d) for d in train_features]\n",
    "train_y = train_labels\n",
    "test_X = [feature(d) for d in test_features]\n",
    "test_y = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularized regression\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(train_X, train_y)\n",
    "theta = clf.coef_\n",
    "train_predictions = clf.predict(train_X)\n",
    "test_predictions = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse: 0.694643534477901\n",
      "test mse: 0.6959140684807902\n"
     ]
    }
   ],
   "source": [
    "train_mse = MSE(train_predictions, train_y)\n",
    "test_mse = MSE(test_predictions, test_y)\n",
    "print(f'train mse: {train_mse}')\n",
    "print(f'test mse: {test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mae: 0.6565156907647727\n",
      "test mae: 0.6560474898234756\n"
     ]
    }
   ],
   "source": [
    "train_mae = MAE(train_predictions, train_y)\n",
    "test_mae = MAE(test_predictions, test_y)\n",
    "print(f'train mae: {train_mae}')\n",
    "print(f'test mae: {test_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSort = list(zip(theta[:-1], words))\n",
    "wordSort.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentDict = dict(zip(words, theta[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22128511446606963"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimentDict['great']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(datum):\n",
    "    sentimentScore = 0\n",
    "    if datum['text']:\n",
    "        r = ''.join([c for c in datum['text'].lower() if not c in punctuation])\n",
    "        for w in r.split():\n",
    "            sentimentScore += sentimentDict.get(w, 0)\n",
    "    return sentimentScore\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = [[1, d['user_avg_rating'], d['bus_avg_rating'], d['num_of_reviews'], sentiment(d)] for d in train_features]\n",
    "test_X = [[1, d['user_avg_rating'], d['bus_avg_rating'], d['num_of_reviews'], sentiment(d)] for d in test_features]\n",
    "\n",
    "train_y = train_labels\n",
    "test_y = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.4642093623008785\n"
     ]
    }
   ],
   "source": [
    "gb_regressor = GradientBoostingRegressor(n_estimators=100, learning_rate=1, random_state=42)\n",
    "\n",
    "gb_regressor.fit(train_X, train_y)\n",
    "\n",
    "predictions = gb_regressor.predict(test_X)\n",
    "\n",
    "mse = mean_squared_error(test_y, predictions)\n",
    "print(f'MSE: {mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = [[1, d['user_avg_rating'], d['bus_avg_rating'],d['num_of_reviews'], d['image_counts'], sentiment(d)] for d in train_features]\n",
    "test_X = [[1, d['user_avg_rating'], d['bus_avg_rating'],d['num_of_reviews'], d['image_counts'], sentiment(d)] for d in test_features]\n",
    "\n",
    "train_y = train_labels\n",
    "test_y = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.46037007083655745\n"
     ]
    }
   ],
   "source": [
    "gb_regressor = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=8, random_state=42)\n",
    "\n",
    "gb_regressor.fit(train_X, train_y)\n",
    "\n",
    "predictions = gb_regressor.predict(test_X)\n",
    "\n",
    "mse = mean_squared_error(test_y, predictions)\n",
    "print(f'MSE: {mse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = [[1, d['user_avg_rating'], d['bus_avg_rating'],d['num_of_reviews'], d['image_counts'], sentiment(d)] for d in train_features]\n",
    "test_X = [[1, d['user_avg_rating'], d['bus_avg_rating'],d['num_of_reviews'], d['image_counts'], sentiment(d)] for d in test_features]\n",
    "\n",
    "train_y = train_labels\n",
    "test_y = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.4612445220573678\n"
     ]
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/xgboost-for-regression/\n",
    "\n",
    "xg_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=8, random_state=42,reg_alpha=0.1, reg_lambda=1.1)\n",
    "xg_model.fit(train_X, train_y)\n",
    "predictions = xg_model.predict(test_X)\n",
    "\n",
    "mse = mean_squared_error(test_y, predictions)\n",
    "print(f'MSE: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 68567 - XGBoost Predicted Rating: 4.88, Actual Rating: 4\n",
      "User 34162 - XGBoost Predicted Rating: 4.07, Actual Rating: 5\n",
      "User 128446 - XGBoost Predicted Rating: 4.57, Actual Rating: 4\n",
      "User 111173 - XGBoost Predicted Rating: 4.09, Actual Rating: 4\n",
      "User 32060 - XGBoost Predicted Rating: 4.36, Actual Rating: 4\n",
      "User 68567 - GradientBoost Predicted Rating: 4.88, Actual Rating: 4\n",
      "User 34162 - GradientBoost Predicted Rating: 4.06, Actual Rating: 5\n",
      "User 128446 - GradientBoost Predicted Rating: 4.57, Actual Rating: 4\n",
      "User 111173 - GradientBoost Predicted Rating: 4.13, Actual Rating: 4\n",
      "User 32060 - GradientBoost Predicted Rating: 4.33, Actual Rating: 4\n"
     ]
    }
   ],
   "source": [
    "random_indices = random.sample(range(len(test_X)), 5)\n",
    "\n",
    "sample_test_X = [test_X[i] for i in random_indices]\n",
    "sample_test_y = [test_y[i] for i in random_indices]\n",
    "\n",
    "xg_predictions = xg_model.predict(sample_test_X)\n",
    "\n",
    "gb_predictions =gb_regressor.predict(sample_test_X)\n",
    "\n",
    "\n",
    "for i, prediction in enumerate(xg_predictions):\n",
    "    print(f\"User {random_indices[i]} - XGBoost Predicted Rating: {prediction:.2f}, Actual Rating: {sample_test_y[i]}\")\n",
    "\n",
    "\n",
    "for i, prediction in enumerate(gb_predictions):\n",
    "    print(f\"User {random_indices[i]} - GradientBoost Predicted Rating: {prediction:.2f}, Actual Rating: {sample_test_y[i]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
